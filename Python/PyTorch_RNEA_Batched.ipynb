{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1201,"status":"ok","timestamp":1714357293457,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"SOSqASJjO16D","outputId":"e0c0fac9-b25c-4b28-c992-c3208cbf3d93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'RNEAPytorch'...\n","remote: Enumerating objects: 295, done.\u001b[K\n","remote: Counting objects: 100% (59/59), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 295 (delta 22), reused 35 (delta 13), pack-reused 236\u001b[K\n","Receiving objects: 100% (295/295), 731.73 KiB | 2.90 MiB/s, done.\n","Resolving deltas: 100% (143/143), done.\n"]}],"source":["!git clone https://github.com/eden-chung/RNEAPytorch.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1714357293457,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"7Mz37HaxO2dD","outputId":"124b3ed0-52bd-4430-f450-23a259a2ba55"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/RNEAPytorch\n"]}],"source":["%cd RNEAPytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"957w7gm0MdFr"},"outputs":[],"source":["from timeit import default_timer as timer\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NryzqP0O8xH"},"outputs":[],"source":["from URDFParser import URDFParser\n","from URDFParser import Robot\n","from util import parseInputs, printUsage, validateRobot, initializeValues, printErr\n","from RBDReference import RBDReference\n","from GRiDCodeGenerator import GRiDCodeGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXkneBe289vT"},"outputs":[],"source":["# Store runtime results from 10 trials, then take average for more accurate runtime\n","mxS_1iter = []\n","mxS_100iter = []\n","vxIv_1iter = []\n","vxIv_100iter = []\n","fpass_1iter = []\n","fpass_100iter = []\n","bpass_1iter = []\n","bpass_100iter = []\n","RNEA_100iter = []"]},{"cell_type":"markdown","metadata":{"id":"yfXyBTdoDLZn"},"source":["### Section 1: RNEA with PyTorch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4936,"status":"ok","timestamp":1714357307385,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"9nu61AfRO9dS","outputId":"59b9fd95-06df-4aec-a591-e9e22ad82945"},"outputs":[{"output_type":"stream","name":"stdout","text":["Link [base] does not have an origin. Assuming this is the fixed world base frame. Else there is an error with your URDF file.\n","Link [base] does not have inertial properties. Assuming this is the fixed world base frame. Else there is an error with your URDF file.\n","------------------------------------------\n","Assumed Input Joint Configuration Ordering\n","------------------------------------------\n","iiwa_joint_1\n","iiwa_joint_2\n","iiwa_joint_3\n","iiwa_joint_4\n","iiwa_joint_5\n","iiwa_joint_6\n","iiwa_joint_7\n","----------------------------\n","Total of n = 7 joints\n","----------------------------\n","q [-0.3369  1.2966 -0.6775 -1.4218 -0.7067 -0.135  -1.1495]\n","qd [ 0.433  -0.4216 -0.6454 -1.8605 -0.0131 -0.4583  0.7412]\n","u [ 0.7418  1.9284 -0.9039  0.0334  1.1799 -1.946   0.3287]\n","n 7\n"]}],"source":["parser = URDFParser()\n","robot = parser.parse('/content/RNEAPytorch/URDFParser/iiwa.urdf')\n","\n","validateRobot(robot)\n","\n","reference = RBDReference(robot)\n","#n is the number of joints\n","q, qd, u, n = initializeValues(robot, MATCH_CPP_RANDOM = True)\n","\n","print(\"q\", q)\n","print(\"qd\", qd)\n","print(\"u\", u)\n","print(\"n\", n)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1714357307385,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"yFQTPumrO-t9","outputId":"2ab4c0cd-26c0-4c0e-e0a7-6831a00076e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["parent_id_arr [-1, 0, 1, 2, 3, 4, 5]\n","parent_id_arr shape: (7,)\n","S_arr shape: (7, 6)\n","S_arr [[0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]]\n","Imat_arr shape: (7, 6, 6)\n","Imat_arr: [[[ 0.2091  0.      0.      0.     -0.6912 -0.1728]\n","  [ 0.      0.1989 -0.0003  0.6912  0.      0.    ]\n","  [ 0.     -0.0003  0.0227  0.1728  0.      0.    ]\n","  [ 0.      0.6912  0.1728  5.76    0.      0.    ]\n","  [-0.6912  0.      0.      0.      5.76    0.    ]\n","  [-0.1728  0.      0.      0.      0.      5.76  ]]\n","\n"," [[ 0.0971 -0.     -0.      0.     -0.2667  0.3746]\n","  [-0.      0.0528 -0.      0.2667  0.     -0.0019]\n","  [-0.     -0.      0.0552 -0.3746  0.0019  0.    ]\n","  [ 0.      0.2667 -0.3746  6.35    0.      0.    ]\n","  [-0.2667  0.      0.0019  0.      6.35    0.    ]\n","  [ 0.3746 -0.0019  0.      0.      0.      6.35  ]]\n","\n"," [[ 0.1496  0.      0.      0.     -0.455   0.105 ]\n","  [ 0.      0.1421  0.0003  0.455   0.      0.    ]\n","  [ 0.      0.0003  0.014  -0.105   0.      0.    ]\n","  [ 0.      0.455  -0.105   3.5     0.      0.    ]\n","  [-0.455   0.      0.      0.      3.5     0.    ]\n","  [ 0.105   0.      0.      0.      0.      3.5   ]]\n","\n"," [[ 0.0566  0.      0.      0.     -0.119   0.2345]\n","  [ 0.      0.0245  0.      0.119   0.      0.    ]\n","  [ 0.      0.      0.0374 -0.2345  0.      0.    ]\n","  [ 0.      0.119  -0.2345  3.5     0.      0.    ]\n","  [-0.119   0.      0.      0.      3.5     0.    ]\n","  [ 0.2345  0.      0.      0.      0.      3.5   ]]\n","\n"," [[ 0.0536 -0.      0.      0.     -0.266   0.0735]\n","  [-0.      0.0491  0.      0.266   0.     -0.0003]\n","  [ 0.      0.      0.0075 -0.0735  0.0003  0.    ]\n","  [ 0.      0.266  -0.0735  3.5     0.      0.    ]\n","  [-0.266   0.      0.0003  0.      3.5     0.    ]\n","  [ 0.0735 -0.0003  0.      0.      0.      3.5   ]]\n","\n"," [[ 0.0049  0.      0.      0.     -0.0007  0.0011]\n","  [ 0.      0.0047 -0.      0.0007  0.      0.    ]\n","  [ 0.     -0.      0.0036 -0.0011  0.      0.    ]\n","  [ 0.      0.0007 -0.0011  1.8     0.      0.    ]\n","  [-0.0007  0.      0.      0.      1.8     0.    ]\n","  [ 0.0011  0.      0.      0.      0.      1.8   ]]\n","\n"," [[ 0.006   0.      0.      0.     -0.024   0.    ]\n","  [ 0.      0.006   0.      0.024   0.      0.    ]\n","  [ 0.      0.      0.005   0.      0.      0.    ]\n","  [ 0.      0.024   0.      1.2     0.      0.    ]\n","  [-0.024   0.      0.      0.      1.2     0.    ]\n","  [ 0.      0.      0.      0.      0.      1.2   ]]]\n"]}],"source":["#initialize robot matrices & vectors\n","parent_id_arr = []\n","S_arr = []\n","Imat_arr = []\n","for ind in range(n):\n","  parent_id_arr.append(robot.get_parent_id(ind))\n","  S_arr.append(robot.get_S_by_id(ind).astype(np.float64))\n","  Imat_arr.append(robot.get_Imat_by_id(ind))\n","\n","print(\"parent_id_arr\", parent_id_arr)\n","parent_id_arr = np.array(parent_id_arr)\n","print(\"parent_id_arr shape:\", parent_id_arr.shape)\n","S_arr = np.array(S_arr)\n","print(\"S_arr shape:\", S_arr.shape)\n","print(\"S_arr\", S_arr)\n","Imat_arr = np.array(Imat_arr)\n","print(\"Imat_arr shape:\", Imat_arr.shape)\n","print(\"Imat_arr:\", Imat_arr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwUCf6PFPAMx"},"outputs":[],"source":["#write xmat functions to file\n","import array\n","import sys\n","import os\n","import inspect\n","\n","for ind in range(n):\n","  with open(f'/content/xmat{ind}.py', 'w') as f:\n","      original_stdout = sys.stdout\n","      sys.stdout = f\n","      try:\n","          print(\"from numpy import array, sin, cos\")\n","          print()\n","          content = robot.get_Xmat_Func_by_id(ind)\n","          source_code = inspect.getsource(content)\n","          print(source_code)\n","          # print(content)\n","      finally:\n","          sys.stdout = original_stdout\n","          f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1714357307568,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"c1fgoLXGPCE7","outputId":"aff5615f-fb46-436a-ae19-91733fc80f1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["xmat_func_arr shape: (7, 6, 6)\n","xmat_func_arr [[[ 0.4089 -0.9126  0.      0.      0.      0.    ]\n","  [ 0.9126  0.4089  0.      0.      0.      0.    ]\n","  [ 0.      0.      1.      0.      0.      0.    ]\n","  [ 0.1437  0.0644  0.      0.4089 -0.9126  0.    ]\n","  [-0.0644  0.1437  0.      0.9126  0.4089  0.    ]\n","  [ 0.      0.      0.      0.      0.      1.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [ 0.     -0.0828  0.     -0.4089  0.     -0.9126]\n","  [ 0.     -0.1848  0.     -0.9126  0.      0.4089]\n","  [-0.2025  0.      0.      0.      1.      0.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [-0.1866  0.      0.0836 -0.4089  0.     -0.9126]\n","  [ 0.0836  0.      0.1866 -0.9126  0.      0.4089]\n","  [ 0.      0.      0.      0.      1.      0.    ]]\n","\n"," [[ 0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [ 0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.     -1.      0.      0.      0.      0.    ]\n","  [ 0.      0.0881  0.      0.4089  0.     -0.9126]\n","  [ 0.      0.1967  0.      0.9126  0.      0.4089]\n","  [ 0.2155  0.      0.      0.     -1.      0.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [-0.1684  0.      0.0754 -0.4089  0.     -0.9126]\n","  [ 0.0754  0.      0.1684 -0.9126  0.      0.4089]\n","  [ 0.      0.      0.      0.      1.      0.    ]]\n","\n"," [[ 0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [ 0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.     -1.      0.      0.      0.      0.    ]\n","  [ 0.      0.0881  0.      0.4089  0.     -0.9126]\n","  [ 0.      0.1967  0.      0.9126  0.      0.4089]\n","  [ 0.2155  0.      0.      0.     -1.      0.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [-0.0739  0.      0.0331 -0.4089  0.     -0.9126]\n","  [ 0.0331  0.      0.0739 -0.9126  0.      0.4089]\n","  [ 0.      0.      0.      0.      1.      0.    ]]]\n"]}],"source":["#store xmat functions into xmat array\n","py_file_location = \"/content\"\n","sys.path.append(os.path.abspath(py_file_location))\n","import xmat0, xmat1, xmat2, xmat3, xmat4, xmat5, xmat6\n","\n","xmat_func_arr = []\n","xmat_func_arr.append(xmat0._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat1._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat2._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat3._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat4._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat5._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat6._lambdifygenerated(q[ind]))\n","\n","xmat_func_arr = np.array(xmat_func_arr)\n","print(\"xmat_func_arr shape:\", xmat_func_arr.shape)\n","print(\"xmat_func_arr\", xmat_func_arr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyQj1iz7QI2Y"},"outputs":[],"source":["def cross_operator_batched(d_vec, d_output):\n","\n","      d_output[0, 1, :] = -d_vec[2, :]\n","      d_output[0, 2, :] = d_vec[1, :]\n","      d_output[1, 0, :] = d_vec[2, :]\n","      d_output[1, 2, :] = -d_vec[0, :]\n","      d_output[2, 0, :] = -d_vec[1, :]\n","      d_output[2, 1, :] = d_vec[0, :]\n","\n","      d_output[3, 1, :] = -d_vec[5, :]\n","      d_output[3, 2, :] = d_vec[4, :]\n","      d_output[3, 4, :] = -d_vec[2, :]\n","      d_output[3, 5, :] = d_vec[1, :]\n","      d_output[4, 0, :] = d_vec[5, :]\n","      d_output[4, 2, :] = -d_vec[3, :]\n","      d_output[4, 3, :] = d_vec[2, :]\n","      d_output[4, 5, :] = -d_vec[0, :]\n","      d_output[5, 0, :] = -d_vec[4, :]\n","      d_output[5, 1, :] = d_vec[3, :]\n","      d_output[5, 3, :] = -d_vec[1, :]\n","      d_output[5, 4, :] = d_vec[0, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1714357307568,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"X7dolUZ9PD4e","outputId":"157b1a3b-85b5-460f-b535-f19172f77aa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["xmat_func_arr shape: (7, 6, 6)\n","xmat_func_arr [[[ 0.4089 -0.9126  0.      0.      0.      0.    ]\n","  [ 0.9126  0.4089  0.      0.      0.      0.    ]\n","  [ 0.      0.      1.      0.      0.      0.    ]\n","  [ 0.1437  0.0644  0.      0.4089 -0.9126  0.    ]\n","  [-0.0644  0.1437  0.      0.9126  0.4089  0.    ]\n","  [ 0.      0.      0.      0.      0.      1.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [ 0.     -0.0828  0.     -0.4089  0.     -0.9126]\n","  [ 0.     -0.1848  0.     -0.9126  0.      0.4089]\n","  [-0.2025  0.      0.      0.      1.      0.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [-0.1866  0.      0.0836 -0.4089  0.     -0.9126]\n","  [ 0.0836  0.      0.1866 -0.9126  0.      0.4089]\n","  [ 0.      0.      0.      0.      1.      0.    ]]\n","\n"," [[ 0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [ 0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.     -1.      0.      0.      0.      0.    ]\n","  [ 0.      0.0881  0.      0.4089  0.     -0.9126]\n","  [ 0.      0.1967  0.      0.9126  0.      0.4089]\n","  [ 0.2155  0.      0.      0.     -1.      0.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [-0.1684  0.      0.0754 -0.4089  0.     -0.9126]\n","  [ 0.0754  0.      0.1684 -0.9126  0.      0.4089]\n","  [ 0.      0.      0.      0.      1.      0.    ]]\n","\n"," [[ 0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [ 0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.     -1.      0.      0.      0.      0.    ]\n","  [ 0.      0.0881  0.      0.4089  0.     -0.9126]\n","  [ 0.      0.1967  0.      0.9126  0.      0.4089]\n","  [ 0.2155  0.      0.      0.     -1.      0.    ]]\n","\n"," [[-0.4089  0.     -0.9126  0.      0.      0.    ]\n","  [-0.9126  0.      0.4089  0.      0.      0.    ]\n","  [ 0.      1.      0.      0.      0.      0.    ]\n","  [-0.0739  0.      0.0331 -0.4089  0.     -0.9126]\n","  [ 0.0331  0.      0.0739 -0.9126  0.      0.4089]\n","  [ 0.      0.      0.      0.      1.      0.    ]]]\n"]}],"source":["#store xmat functions into xmat array\n","py_file_location = \"/content\"\n","sys.path.append(os.path.abspath(py_file_location))\n","import xmat0, xmat1, xmat2, xmat3, xmat4, xmat5, xmat6\n","\n","xmat_func_arr = []\n","xmat_func_arr.append(xmat0._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat1._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat2._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat3._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat4._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat5._lambdifygenerated(q[ind]))\n","xmat_func_arr.append(xmat6._lambdifygenerated(q[ind]))\n","\n","xmat_func_arr = np.array(xmat_func_arr)\n","print(\"xmat_func_arr shape:\", xmat_func_arr.shape)\n","print(\"xmat_func_arr\", xmat_func_arr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1714357308117,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"dQLC_I6_PGTI","outputId":"1fdaf8b2-6898-4cbf-ea22-80d39f65172c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cross operator output shape:  torch.Size([6, 6, 100])\n","GPU Batched: 0.058734044000004815\n"]}],"source":["# COMPARING to batched\n","batch_size = 100\n","h_vec_batched = np.ones((6,batch_size),  dtype=np.float64)\n","h_output_batched = np.zeros((6, 6, batch_size), dtype=np.float64)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","h_vec_batched = torch.as_tensor(h_vec_batched, device=device)\n","h_output_batched = torch.as_tensor(h_output_batched, device=device)\n","\n","#on CPU\n","cross_operator_batched(h_vec_batched, h_output_batched) #warm-up once\n","print(\"cross operator output shape: \", h_output_batched.shape)\n","startnext = timer()\n","for i in range(100):\n","  cross_operator_batched(h_vec_batched, h_output_batched)\n","print(\"GPU Batched: \" + str(timer() - startnext))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ld72oMlPMdK"},"outputs":[],"source":["def mxS_pytorch(S, vec, vec_output, mxS_output=None, alpha=None):\n","    # Input:\n","    # S, vec, vec_output, mxS_output, alpha are all torch tensor\n","    # returns the spatial cross product between vectors S and vec. vec=[v0, v1 ... vn] and S = [s0, s1, s2, s3, s4, s5]\n","    # derivative of spatial motion vector = v x m\n","    # print(\"vec shape: \" + str(vec.shape))\n","    # print(\"vec_output shape: \" + str(vec_output.shape))\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    cross_operator_batched(vec, vec_output)\n","\n","    mxS_output = alpha * torch.sum(vec_output * S, dim=1)\n","\n","    return mxS_output.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1714357308117,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"iJlAkIiFPNC_","outputId":"a88fc59f-5ab6-4b54-ce29-f662316ba8c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 iteration: 0.07657030499996154\n","100 iterations: 0.09000752000002876\n"]}],"source":["# COMPARING to batched\n","batch_size = 100\n","# vec is a 6 by 1 matrix\n","h_vec_batched = np.ones((6,batch_size),  dtype=np.float64)\n","\n","#S should be a 6 by 1 matrix\n","h_s_vec_batched = np.ones((6, 1, batch_size),  dtype=np.float64)\n","\n","#vec output is a 6 by 6 matrix\n","h_output_batched = np.zeros((6, 6, batch_size), dtype=np.float64)\n","\n","#mxS output is a 6 by 6 matrix\n","#TODO: mxS output should be (6, ) not (6, 6), need to change in CPU batched\n","h_mxS_output_batched = np.zeros((6, batch_size), dtype=np.float64)\n","\n","alpha = 0.1\n","\n","# Convert input to torch tensor type\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","h_vec_batched = torch.as_tensor(h_vec_batched, device=device)\n","h_s_vec_batched = torch.as_tensor(h_s_vec_batched, device=device)\n","h_output_batched = torch.as_tensor(h_output_batched, device=device)\n","h_mxS_output_batched = torch.as_tensor(h_mxS_output_batched, device=device)\n","alpha = torch.tensor(alpha, device=device)\n","\n","startnext = timer()\n","mxS_pytorch(h_s_vec_batched, h_vec_batched, h_output_batched, h_mxS_output_batched, alpha) #warm-up once\n","totalTime = timer() - startnext\n","print(\"1 iteration: \" + str(totalTime))\n","mxS_1iter.append(totalTime)\n","\n","startnext = timer()\n","for i in range(100):\n","  mxS_pytorch(h_s_vec_batched, h_vec_batched, h_output_batched, h_mxS_output_batched, alpha)\n","totalTime = timer() - startnext\n","print(\"100 iterations: \" + str(timer() - startnext))\n","mxS_100iter.append(totalTime)\n","# print(mxS_pytorch(h_s_vec_batched, h_vec_batched, h_output_batched, h_mxS_output_batched, alpha).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNuP5ZAiQgZT"},"outputs":[],"source":["def vxIv_pytorch(vec, Imat, res, batch_size):\n","    # Input:\n","    # vec, Imat, res, batch_size: should be of type torch tensors\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    temp = torch.sum(Imat * vec[:, None, :], dim=1)\n","    temp = temp.view(-1)\n","\n","    vecXIvec = torch.zeros((6, batch_size), dtype=torch.float64, device=device)\n","\n","    vecXIvec[0] = -vec[2]*temp[1]   +  vec[1]*temp[2] + -vec[2+3]*temp[1+3] +  vec[1+3]*temp[2+3]\n","    vecXIvec[1] =  vec[2]*temp[0]   + -vec[0]*temp[2] +  vec[2+3]*temp[0+3] + -vec[0+3]*temp[2+3]\n","    vecXIvec[2] = -vec[1]*temp[0]   +  vec[0]*temp[1] + -vec[1+3]*temp[0+3] +  vec[0+3]*temp[1+3]\n","    vecXIvec[3] = -vec[2]*temp[1+3] +  vec[1]*temp[2+3]\n","    vecXIvec[4] =  vec[2]*temp[0+3] + -vec[0]*temp[2+3]\n","    vecXIvec[5] = -vec[1]*temp[0+3] +  vec[0]*temp[1+3]\n","    res = vecXIvec\n","\n","    return res.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1714357308537,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"20tUHwdhQoWw","outputId":"566fcef0-abec-42f8-9332-204d43c8038f"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 iteration: 0.061252841999987595\n","100 iterations: 0.12149604500001487\n"]}],"source":["# COMPARING to batched\n","batch_size = 10000\n","\n","\n","h_vec_batched = np.ones((6, batch_size),  dtype=np.float64)\n","h_I_batched = np.ones((6, 6, batch_size),  dtype=np.float64)\n","h_output_batched = np.zeros((6, batch_size), dtype=np.float64)\n","h_mxS_output_batched = np.zeros((6, batch_size), dtype=np.float64)\n","\n","alpha = 0.1\n","\n","# Convert input to torch tensor type\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","h_vec_batched = torch.as_tensor(h_vec_batched, device=device)\n","h_I_batched= torch.as_tensor(h_I_batched, device=device)\n","h_output_batched = torch.as_tensor(h_output_batched, device=device)\n","h_mxS_output_batched = torch.as_tensor(h_mxS_output_batched, device=device)\n","alpha = torch.tensor(alpha, device=device)\n","\n","#GPU\n","startnext = timer()\n","vxIv_pytorch(h_vec_batched, h_I_batched, h_output_batched, batch_size) #warm-up once\n","totalTime = timer() - startnext\n","print(\"1 iteration: \" + str(totalTime))\n","vxIv_1iter.append(totalTime)\n","\n","# print(\"vxIV shape: \", h_output_batched.shape)\n","#testing in loop of 100\n","startnext = timer()\n","for i in range(100):\n","  vxIv_pytorch(h_vec_batched, h_I_batched, h_output_batched, batch_size)\n","totalTime = timer() - startnext\n","print(\"100 iterations: \" + str(totalTime))\n","vxIv_100iter.append(totalTime)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4t1Dk53BQ2pp"},"outputs":[],"source":["def rnea_fpass_pytorch(num_joints, parent_id_arr, xmat_func_arr, S_arr, Imat_arr, crOp_output, mxS_output, vxIv_output, batch_size, q, qd, qdd=None, GRAVITY=-9.81):\n","    \"\"\"\n","    Forward Pass for RNEA algorithm. Computes the velocity and acceleration of each body in the tree necessary to produce a certain trajector\n","\n","    OUTPUT:\n","    v : input qd is specifying value within configuration space with assumption of one degree of freedom.\n","    Output velocity is in general body coordinates and specifies motion in full 6 degrees of freedom\n","    \"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    n = num_joints\n","\n","    v = torch.zeros((6, n, batch_size), device=device)\n","    a = torch.zeros((6, n, batch_size), device=device)\n","    f = torch.zeros((6, n, batch_size), device=device)\n","\n","    gravity_vec = torch.zeros((6, batch_size), device=device)\n","    gravity_vec[5, :] = -GRAVITY\n","\n","    # parent_id_arr = torch.from_numpy(parent_id_arr).to(device)\n","    # xmat_func_arr = torch.from_numpy(xmat_func_arr).to(device)\n","    # S_arr = torch.from_numpy(S_arr).to(device)\n","    # Imat_arr = torch.from_numpy(Imat_arr).to(device)\n","    # crOp_output = torch.from_numpy(crOp_output).to(device)\n","    # mxS_output = torch.from_numpy(mxS_output).to(device)\n","    # vxIv_output = torch.from_numpy(vxIv_output).to(device)\n","    # q = torch.from_numpy(q).to(device)\n","    # qd = torch.from_numpy(qd).to(device)\n","    if qdd is not None:\n","        qdd = torch.from_numpy(qdd).to(device)\n","\n","    for ind in range(n):\n","        parent_ind = parent_id_arr[ind]\n","\n","        Xmat = xmat_func_arr[ind, :, :, :]\n","        S = S_arr[ind]\n","\n","        if parent_ind == -1:\n","            a[:, ind, :] = torch.sum(Xmat * gravity_vec[:, None, :], dim=1)\n","        else:\n","            v[:, ind, :] = torch.sum(Xmat * v[:, parent_ind, :], dim=1)\n","            a[:, ind, :] = torch.sum(Xmat * a[:, parent_ind, :], dim=1)\n","\n","        v[:,ind, :] = torch.add(v[:,ind, :], S*qd[ind])\n","\n","        mxS_pytorch(S, v[:,ind, :], crOp_output, mxS_output, qd[ind])\n","        a[:, ind, :] = torch.add(a[:, ind, :], mxS_output)\n","        if qdd is not None:\n","            a[:,ind, :] = torch.add(a[:,ind, :], S*qdd[ind])\n","\n","        Imat = Imat_arr[ind, :, :]\n","\n","        temp = torch.sum(Imat*a[:, ind, :], dim=1)\n","        vxIv_pytorch(v[:,ind, :],Imat, vxIv_output, batch_size)\n","        f[:, ind, :] = torch.add(temp, vxIv_output)\n","\n","        return (v,a,f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEwkQ0v8RCjO"},"outputs":[],"source":["batch_size = 10000\n","\n","\n","h_xmat_func_arr_batched = np.repeat(xmat_func_arr[:, :, :, np.newaxis], batch_size, axis=3)\n","h_S_arr_batched = np.repeat(S_arr[:, :, np.newaxis], batch_size, axis=2)\n","\n","h_Imat_arr_batched = np.repeat(Imat_arr[:, :, :, np.newaxis], batch_size, axis=3)\n","h_q_batched = np.repeat(q[:, np.newaxis], batch_size, axis=1)\n","h_qd_batched = np.repeat(qd[:, np.newaxis], batch_size, axis=1)\n","\n","h_crOp_output_batched = np.zeros((6, 6, batch_size), dtype=np.float64)\n","h_mxS_output_batched = np.zeros((6, batch_size), dtype=np.float64)\n","h_vxIv_output_batched = np.zeros((6, batch_size), dtype=np.float64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QEUrwIwQ-rX"},"outputs":[],"source":["# Convert to tensor\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","parent_id_arr = torch.from_numpy(parent_id_arr).to(device)\n","h_xmat_func_arr_batched = torch.from_numpy(h_xmat_func_arr_batched).to(device)\n","h_S_arr_batched = torch.from_numpy(h_S_arr_batched).to(device)\n","h_Imat_arr_batched = torch.from_numpy(h_Imat_arr_batched).to(device)\n","h_q_batched = torch.from_numpy(h_q_batched).to(device)\n","h_qd_batched = torch.from_numpy(h_qd_batched).to(device)\n","h_crOp_output_batched = torch.from_numpy(h_crOp_output_batched).to(device)\n","h_mxS_output_batched  = torch.from_numpy(h_mxS_output_batched ).to(device)\n","h_vxIv_output_batched = torch.from_numpy(h_vxIv_output_batched).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1714357308852,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"LjeTnAfvRZbV","outputId":"6402b5c8-db9d-4442-8a5d-b8a263d06cfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 iteration: 0.0768854250000004\n","100 iterations: 0.2976948290000223\n"]}],"source":["itr = 100\n","\n","startnext = timer()\n","v,a,f = rnea_fpass_pytorch(n, parent_id_arr, h_xmat_func_arr_batched, h_S_arr_batched,\n","                         h_Imat_arr_batched, h_crOp_output_batched,\n","                         h_mxS_output_batched, h_vxIv_output_batched, batch_size,\n","                         h_q_batched, h_qd_batched, qdd = None, GRAVITY = -9.81)\n","totalTime = timer() - startnext\n","print(\"1 iteration: \" + str(totalTime))\n","fpass_1iter.append(totalTime)\n","\n","startnext = timer()\n","for i in range(itr):\n","  rnea_fpass_pytorch(n, parent_id_arr, h_xmat_func_arr_batched, h_S_arr_batched,\n","                         h_Imat_arr_batched, h_crOp_output_batched,\n","                         h_mxS_output_batched, h_vxIv_output_batched, batch_size,\n","                         h_q_batched, h_qd_batched, qdd = None, GRAVITY = -9.81)\n","totalTime = timer() - startnext\n","print(\"100 iterations: \" + str(totalTime))\n","fpass_100iter.append(totalTime)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxWcDr6cSUTF"},"outputs":[],"source":["def rnea_bpass_pytorch(S_arr, parent_id_arr, xmat_func_arr, q, qd, f, USE_VELOCITY_DAMPING = False):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    n = len(q)\n","    c = torch.zeros((n, batch_size), device=device)\n","\n","    for ind in range(n-1, -1, -1):\n","        S = S_arr[ind]\n","        c[ind, :] = torch.sum(S * f[:, ind, :], dim=0)\n","\n","        parent_ind = parent_id_arr[ind]\n","        if parent_ind != -1:\n","            Xmat = xmat_func_arr[ind, :, :]\n","            temp = torch.sum(Xmat * f[:, ind, :], dim=1)\n","\n","            # Ensure temp is correctly shaped for addition\n","            # temp = temp.transpose(0, 1)  # Swap the dimensions if necessary\n","            temp.unsqueeze(1)\n","            f[:, parent_ind, :] = torch.add(f[:, parent_ind, :], temp)\n","\n","    return (c, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1714357309185,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"Z6_-HRDeSXqO","outputId":"053b25ce-eaa6-43d5-d7f8-7bb313da7dbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 iteration: 0.005318013000021438\n","100 iterations: 0.2560340089999613\n"]}],"source":["itr = 100\n","#for reference, batch_size is 10000 above\n","v,a,f = rnea_fpass_pytorch(n, parent_id_arr, h_xmat_func_arr_batched, h_S_arr_batched,\n","                         h_Imat_arr_batched, h_crOp_output_batched,\n","                         h_mxS_output_batched, h_vxIv_output_batched, batch_size,\n","                         h_q_batched, h_qd_batched, qdd = None, GRAVITY = -9.81)\n","\n","startnext = timer()\n","c, f = rnea_bpass_pytorch(h_S_arr_batched, parent_id_arr, h_xmat_func_arr_batched, h_q_batched, h_qd_batched, f, USE_VELOCITY_DAMPING = False)\n","totalTime = timer() - startnext\n","print(\"1 iteration: \" + str(totalTime))\n","bpass_1iter.append(totalTime)\n","\n","startnext = timer()\n","for i in range(itr):\n","  rnea_bpass_pytorch(h_S_arr_batched, parent_id_arr, h_xmat_func_arr_batched, h_q_batched, h_qd_batched, f, USE_VELOCITY_DAMPING = False)\n","totalTime = timer() - startnext\n","print(\"100 iterations: \" + str(totalTime))\n","bpass_100iter.append(totalTime)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNqT-kirTSWS"},"outputs":[],"source":["def rnea_pytorch(q, qd, qdd = None, GRAVITY = -9.81, USE_VELOCITY_DAMPING = False):\n","\n","      # first do the forward pass\n","      v,a,f = rnea_fpass_pytorch(n, parent_id_arr, h_xmat_func_arr_batched, h_S_arr_batched,\n","                         h_Imat_arr_batched, h_crOp_output_batched,\n","                         h_mxS_output_batched, h_vxIv_output_batched, batch_size,\n","                         h_q_batched, h_qd_batched, qdd = None, GRAVITY = -9.81)\n","\n","      # then do the backward pass\n","      (c,f) = rnea_bpass_pytorch(h_S_arr_batched, parent_id_arr,h_xmat_func_arr_batched,\n","                               h_q_batched, h_qd_batched,\n","                               f, USE_VELOCITY_DAMPING = False)\n","      return (c,v,a,f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1714357309599,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"I_C6jTKWTMJX","outputId":"cea7f2f1-6813-4c0c-88c6-ec2ed6b5fbcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Batched RNEA: 0.4841517369999906\n"]}],"source":["startnext = timer()\n","for i in range(itr):\n","    rnea_pytorch(q, qd, qdd = None, GRAVITY = -9.81, USE_VELOCITY_DAMPING = False)\n","totalTime = timer() - startnext\n","print(\"GPU Batched RNEA: \" + str(totalTime))\n","RNEA_100iter.append(totalTime)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-tgqwUb-6dw"},"outputs":[],"source":["mxS_1iter_avg = sum(mxS_1iter) / len(mxS_1iter)\n","mxS_100iter_avg = sum(mxS_100iter) / len(mxS_100iter)\n","vxIv_1iter_avg = sum(vxIv_1iter) / len(vxIv_1iter)\n","vxIv_100iter_avg = sum(vxIv_100iter) / len(vxIv_100iter)\n","fpass_1iter_avg = sum(fpass_1iter) / len(fpass_1iter)\n","fpass_100iter_avg = sum(fpass_100iter) / len(fpass_100iter)\n","bpass_1iter_avg = sum(bpass_1iter) / len(bpass_1iter)\n","bpass_100iter_avg = sum(bpass_100iter) / len(bpass_100iter)\n","RNEA_100iter_avg = sum(RNEA_100iter) / len(RNEA_100iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1714357309814,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"a6844usp_E1m","outputId":"17aa5382-f2b7-4624-c293-e95d2c4c48a2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.07657030499996154"]},"metadata":{},"execution_count":26}],"source":["mxS_1iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1714357309815,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"D47w0psM_GgK","outputId":"40ef1b7b-6b53-4874-e990-6c25ecd441fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.08991553300000987"]},"metadata":{},"execution_count":27}],"source":["mxS_100iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1714357309815,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"6KWDSBR-_IOS","outputId":"04eefc93-53c8-4713-eda8-e82a866e111a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.061252841999987595"]},"metadata":{},"execution_count":28}],"source":["vxIv_1iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714357309815,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"hJyli_2A_Jab","outputId":"93870c96-3dbe-47ed-a65a-656a916a1d31"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.12149604500001487"]},"metadata":{},"execution_count":29}],"source":["vxIv_100iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714357309815,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"cUtWmjPY_KKr","outputId":"8a6e8467-078a-4547-be77-653f5b20145f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0768854250000004"]},"metadata":{},"execution_count":30}],"source":["fpass_1iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1714357309815,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"FPXaWorM_LMt","outputId":"4c858a4d-d83b-49a2-9dcd-0ce820dc5d1c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2976948290000223"]},"metadata":{},"execution_count":31}],"source":["fpass_100iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1714357309815,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"UeywRiEY_L5Z","outputId":"606a6da5-1e18-49cd-fbb8-e7543cb92afd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.005318013000021438"]},"metadata":{},"execution_count":32}],"source":["bpass_1iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1714357309816,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"N2KU7BT-_Nlu","outputId":"71e34102-e684-410c-dffd-a5295647473e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2560340089999613"]},"metadata":{},"execution_count":33}],"source":["bpass_100iter_avg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1714357309816,"user":{"displayName":"Siying Ding","userId":"16983141864285532709"},"user_tz":240},"id":"jA85TjE9_OP1","outputId":"f1a14388-9735-4687-f1cf-a8ef2545d79d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4841517369999906"]},"metadata":{},"execution_count":34}],"source":["RNEA_100iter_avg"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}